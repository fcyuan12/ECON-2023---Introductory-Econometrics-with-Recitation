---
title: "TA Session 3"
author: "Chi-Yuan Fang"
date: "March 16, 2021"
output: 
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(kableExtra)
```

# Introduction

## TA Information

TA: Chi-Yuan Fang

TA sessions: Tuesday 1:20 – 3:10 PM (SS 501) 

Email: r09323017@ntu.edu.tw

Office hours: Friday 2:00 – 3:30 PM or by appointments (SS 643)

Class group on Facebook: Statistics (Fall 2020) and Econometrics (Spring 2021) 

<https://www.facebook.com/groups/452292659024369/>

Because screens are not clear in SS 501, I will provide the link of live streaming in the group.


## TA Sessions Schedule

| Week | TA Sessions    | Quiz | Content | Remind |
|------|-------------|------|-------------------------|-----------------|
|  1   | 02/23: No class| | | | |
|  2   | 03/02: Class 1 | | Function, Confidence Interval, T test | 03/10 Turn in HW1 |
|  3   | 03/09: Class 2 | | Loops, Linear Model | 03/10 Turn in HW1, 03/16 Quiz 1 |
|  4   | 03/16: Class 3 | Quiz 1 | OLS | 03/24 Turn in HW2 |
|  5   | 03/23: Class 4 | |  | 03/24 Turn in HW2, 03/30 Quiz 2 |
|  6   | 03/30: Class 5 | Quiz 2 |  | 04/14 Turn in HW3 |
|  7   | 04/06: No class | | | 04/14 Turn in HW3 |
|  8   | 04/13: Class 6 | |  | 04/14 Turn in HW3, 04/20 Quiz 3 |
|  9   | 04/20: Class 7 | Quiz 3 | | **04/28 Midterm** |
| 10   | 04/27: Class 8 | | Review and Q&A | **04/28 Midterm**, 05/05 Turn in HW4 |
| 11   | 05/04: Class 9| |  | 05/05 Turn in HW4, 05/11 Quiz 4 |
| 12   | 05/11: Class 10| Quiz 4 |  | 05/19 Turn in HW5 |
| 13   | 05/18: Class 11| |  | 05/19 Turn in HW5, 05/25 Quiz 5 |
| 14   | 05/25: Class 12| Quiz 5 |  | 06/02 Turn in HW6 |
| 15   | 06/01: Class 13| |  | 06/02 Turn in HW6, 06/08 Quiz 6 |
| 16   | 06/08: Class 14| Quiz 6 | Review and Q&A | **06/16 Final Exam** | 
| 17   | 06/15: No class| | | **06/16 Final Exam** | 
| 18   | 06/22: No class| | |  |

## Reference

Introduction to Econometrics with R

<https://www.econometrics-with-r.org>

R for Data Science 

<https://r4ds.had.co.nz>

R Markdown

<https://rmarkdown.rstudio.com>

Introduction to R Markdown

<https://rpubs.com/brandonkopp/RMarkdown>

What is a good book on learning R with examples?

<https://www.quora.com/What-is-a-good-book-on-learning-R-with-examples>


# Empirical Exercise 4.2


> On the text website, <http://www.pearsonglobaleditions.com>, you will find the data file **Earnings_and_Height**, which contains data on earnings, height, and other characteristics of a random sample of U.S. workers. A detailed description is given in **Earnings_and_Height_Description**, also available on the website. In this exercise, you will investigate the relationship between earnings and height.

> a. What is the median value of height in the sample?

**Solution**

```{r}
# import data 
#install.packages("readxl")
library(readxl)
Earnings_and_Height <- read_xlsx("Earnings_and_Height/Earnings_and_Height.xlsx")

median(Earnings_and_Height$height)

```


> b. 
>     i. Estimate average earnings for workers whose height is at most
67 inches.
>     ii. Estimate average earnings for workers whose height is greater than
67 inches.
>     iii. On average, do taller workers earn more than shorter workers? How
much more? What is a 95\% confidence interval for the difference in average earnings?

**Solution**

```{r}
# create "group" variable
group <- c()

for (i in 1:length(Earnings_and_Height$height)){
  if (Earnings_and_Height$height[i] <= 67){
    # group 0: height <= 67
    group[i] <- c(0) 
  } else {
    # group 1: height > 67
    group[i] <- c(1) 
  }
}

Earnings_and_Height <- cbind(Earnings_and_Height, group)

E42b <- function(x){
  # sample mean
  mu <- mean(x)
  
  # sample standard deviation (standard error)
  se <- sd(x)/sqrt(length(x))
  
  # test
  test <- t.test(x, 
                 alternative = c("two.sided"),
                 mu = 0, # H0
                 conf.level = 0.95) # alpha = 0.05
  
  # 95% confidence interval
  lower <- round(test$conf.int[1], digit = 4)
  upper <- round(test$conf.int[2], digit = 4)
  CI <- paste(lower, "-"  ,upper)
  
  Table <- data.frame(mu, se, CI)
  colnames(Table) <- c("Mean", "Standard Error", "95% Confidence Interval")
  
  Table

}

# i. # ii.
tapply(Earnings_and_Height$earnings, Earnings_and_Height$group, E42b)

# height <= 67
Earnings_and_Height_i <- Earnings_and_Height[Earnings_and_Height$height <= 67, ]

# height > 67
Earnings_and_Height_ii <- Earnings_and_Height[Earnings_and_Height$height > 67, ]

# iii. 95% CI for difference
t.test(Earnings_and_Height_ii$earnings, Earnings_and_Height_i$earnings, 
       alternative = c("two.sided"),
       mu = 0, # H0
       var.equal = FALSE,
       conf.level = 0.95) # alpha = 0.05

```


> c. Construct a scatterplot of annual earnings $(Earnings)$ on height $(Height)$.
Notice that the points on the plot fall along horizontal lines. (There are only 23 distinct values of $Earnings$). Why? (Hint: Carefully read the detailed data description.)

**Solution**

```{r}
plot(x = Earnings_and_Height$height, 
     y = Earnings_and_Height$earnings,
     pch = 16, # filled circle
     col = "black",
     xlim = c(45, 90),
     ylim = c(0, 85000),
     xlab = "height",
     ylab = "earnings",
     main = "E4.2 (c)")

```

The data documentation reports that individual earnings were reported in 23 brackets, and a single average value is reported for earnings in the same bracket. Thus, the dataset contains 23 distinct values of earnings.


> d. Run a regression of $Earnings$ on $Height$.
>     i. What is the estimated slope?
>     ii. Use the estimated regression to predict earnings for a worker who is 67 inches tall, for a worker who is 70 inches tall, and for a worker who is 65 inches tall.

**Solution**

```{r}
# regression 
E42d <- lm(formula = earnings ~ height, data = Earnings_and_Height)

# i. estimated intercept, estimated slope
summary(E42d)

# predict value
E42d_predict <- function(x){
  E42d$coefficients %*% matrix(c(1, x), ncol = 1)
  
}

# ii. predict value: height = 67
E42d_predict(67)

# ii. predict value: height = 70
E42d_predict(70)

# ii. predict value: height = 65
E42d_predict(65)

```


> e. Suppose height were measured in centimeters instead of inches. Answer
the following questions about the $Earnings$ on $Height$ (in cm) regression.
>     i. What is the estimated slope of the regression?
>     ii. What is the estimated intercept?
>     iii. What is the $R^2$?
>     iv. What is the standard error of the regression?

**Solution**

```{r}
# translates from inches to cm
height_cm <- cm(Earnings_and_Height$height)

Earnings_and_Height <- cbind(Earnings_and_Height, height_cm)

# regression 
E42e <- lm(formula = earnings ~ height_cm, data = Earnings_and_Height)

# i. estimated slope # ii. estimated intercept
# iii. R^2 # iv. SE
summary(E42e)

```


> f. Run a regression of $Earnings$ on $Height$, using data for female workers
only.
>     i. What is the estimated slope?
>     ii. A randomly selected woman is 1 inch taller than the average woman in the sample. Would you predict her earnings to be higher or lower than the average earnings for women in the sample? By how much?

**Solution**

```{r}
# female
Earnings_and_Height_f <- Earnings_and_Height[Earnings_and_Height$sex == 0, ]

# regression 
E42f <- lm(formula = earnings ~ height, data = Earnings_and_Height_f)

# i. estimated slope # ii.
summary(E42f)

```
A women who is one inch taller than average is predicted to have earnings that are \$511.2 per year higher than average.

> g. Repeat (f) for male workers.

**Solution**

```{r}
# male
Earnings_and_Height_g <- Earnings_and_Height[Earnings_and_Height$sex == 1, ]

# regression 
E42g <- lm(formula = earnings ~ height, data = Earnings_and_Height_g)

# i. estimated slope # ii.
summary(E42g)
```
A man who is one inch taller than average is predicted to have earnings that are \$1306.9 per year higher than average.

> h. Do you think that height is uncorrelated with other factors that cause
earning? That is, do you think that the regression error term, ui has a conditional mean of 0 given $Height$ $(X_i)$? (You will investigate this more in the Earnings and Height exercises in later chapters.)

**Solution**

Height may be correlated with other factors that cause earnings. For example, height may be correlated with “strength,” and in some occupations, stronger workers may by more productive. There are many other potential factors that may be correlated with height and cause earnings and we will investigate of these in future exercises.

# Empirical Exercise 5.1

> Use the data set **Earnings_and_Height** described in Empirical Exercise 4.2 to carry out the following exercises.

> a. Run a regression of $Earnings$ on $Height$.
>     i. Is the estimated slope statistically significant?
>     ii. Construct a 95\% confidence interval for the slope coefficient.

**Solution**

i. 

*  **Prepare**

$H_0: \beta_{height} = 0$ v.s. $H_1: \beta_{height} \neq 0$

Let the significance level be 0.05.

*  **Calculate**

```{r}
# import data 
library(readxl)
Earnings_and_Height <- read_xlsx("Earnings_and_Height/Earnings_and_Height.xlsx")

E51a_model <- lm(earnings ~ height, data = Earnings_and_Height)

summary(E51a_model)

```

*  **Conclude**

Because $p-value < 0.05$, we reject $H_0$. The estimated slope is statistically significant different from 0.

ii.

In simple regression model 
\begin{align}
    Y_i = \beta_0 + \beta_1 X_i + u_i,
\end{align}
we know
\begin{align}
    \widehat{\beta}_1
    & = \frac{\sum_{i=1}^{n}\left(X_i - \overline{X} \right) \left(Y_i - \overline{Y} \right) }{\sum_{i=1}^{n}\left(X_i - \overline{X} \right)^2} \\
    \widehat{\beta}_0
    & = \overline{Y} - \widehat{\beta}_1 \overline{X} \\
    ESS 
    & = \sum_{i=1}^{n} \left( \widehat{Y}_i - \overline{Y} \right)^2 \\
    TSS
    & = \sum_{i=1}^{n} \left( Y_i - \overline{Y} \right)^2 \\
    SSR 
    & = \sum_{i=1}^{n} \widehat{u}_i^2 
      = \sum_{i=1}^{n} \left( Y_i - \widehat{Y}_i \right)^2 \\
    R^2 
    & = \frac{ESS}{TSS} 
      = 1 - \frac{SSR}{TSS} \\
    \widehat{\sigma}^2 
    & = \frac{\sum_{i=1}^{n} \widehat{u}_i^2}{n - 2} \\
    SE\left( \widehat{\beta}_1 \right)
    & = \sqrt{ \frac{\widehat{\sigma}^2}{\sum_{i=1}^{n} \left(X_i - \overline{X} \right)^2} } \\
    SE\left( \widehat{\beta}_0 \right)
    & = \sqrt{ \widehat{\sigma}^2 \left( \frac{1}{n} +  \frac{\overline{X}^2}{\sum_{i=1}^{n} \left(X_i - \overline{X} \right)^2} \right) } 
\end{align}


```{r}
E51a <- function(x, y){
  # numbers of sample
  n <- length(y)
  
  # sample mean
  xbar <- mean(x)
  ybar <- mean(y)
  
  # OLS coefficient
  b1hat <- cov(x,y)/var(x)
  b0hat <- ybar - b1hat*xbar
  
  yhat <- b0hat + b1hat*x
  
  # explained sum of squares (ESS)
  ESS <- sum((yhat - ybar)^2)
  # total sum of squares (TSS)
  TSS <- sum((y - ybar)^2)
  # sum of squared residuals (SSR)
  SSR <- sum((y - yhat)^2)
  
  # coefficient of determination
  Rsqure <- ESS/TSS
  
  # standard error of the regression
  SER <- sqrt(SSR/(n-2))
  
  # standard error of coefficient
  se_b1hat <- sqrt(SER^2/sum((x - xbar)^2))
  se_b0hat <- sqrt(SER^2* (1/n + xbar^2/sum((x - xbar)^2)))
  
  # 95% CI for b1hat
  lower_b1hat <- round(b1hat - qnorm(0.975, mean = 0, sd = 1)*se_b1hat, digit = 4)
  upper_b1hat <- round(b1hat + qnorm(0.975, mean = 0, sd = 1)*se_b1hat, digit = 4)
  CI_b1hat <- paste(lower_b1hat, "-"  ,upper_b1hat)
  
  # 95% CI for b0hat
  lower_b0hat <- round(b0hat - qnorm(0.975, mean = 0, sd = 1)*se_b0hat, digit = 4)
  upper_b0hat <- round(b0hat + qnorm(0.975, mean = 0, sd = 1)*se_b0hat, digit = 4)
  CI_b0hat <- paste(lower_b0hat, "-"  ,upper_b0hat)  
  
  # coefficient
  coef <- matrix(c(b0hat, se_b0hat, CI_b0hat, b1hat, se_b1hat, CI_b1hat), ncol = 3, byrow = TRUE)
  rownames(coef) <- c("Intercept", "Slope")
  colnames(coef) <- c("Estimate", "Standard Error", "95% Confidence Interval")
  
  result <- list(coef, Rsqure)
  names(result) <- c("Coefficients", "R-squared")
  
  result
} 

E51a(Earnings_and_Height$height, Earnings_and_Height$earnings)
```

> b. Repeat (a) for women.

**Solution**

i. 

*  **Prepare**

$H_0: \beta_{height}^{women} = 0$ v.s. $H_1: \beta_{height}^{women} \neq 0$

Let the significance level be 0.05.

*  **Calculate**

```{r}
# data: woman
Earnings_and_Height_women <- Earnings_and_Height[Earnings_and_Height$sex == 0,]

E51b_model <- lm(earnings ~ height, data = Earnings_and_Height_women)

summary(E51b_model)

```

*  **Conclude**

Because $p-value < 0.05$, we reject $H_0$. The estimated slope is statistically significant different from 0.

ii.

```{r}
E51a(Earnings_and_Height_women$height, Earnings_and_Height_women$earnings)
```


> c. Repeat (a) for men.

**Solution**

i. 

*  **Prepare**

$H_0: \beta_{height}^{men} = 0$ v.s. $H_1: \beta_{height}^{women} \neq 0$

Let the significance level be 0.05.

*  **Calculate**

```{r}
# data: woman
Earnings_and_Height_men <- Earnings_and_Height[Earnings_and_Height$sex == 1,]

E51c_model <- lm(earnings ~ height, data = Earnings_and_Height_men)

summary(E51c_model)

```

*  **Conclude**

Because $p-value < 0.05$, we reject $H_0$. The estimated slope is statistically significant different from 0.

ii.

```{r}
E51a(Earnings_and_Height_men$height, Earnings_and_Height_men$earnings)
```


> d. Test the null hypothesis that the effect of height on earnings is the same for men and women. (Hint: See Exercise 5.15.)

**Solution**

*  **Prepare**

$H_0: \beta_{height}^{men} - \beta_{height}^{women} = 0$ v.s. $H_1: \beta_{height}^{men} - \beta_{height}^{women} \neq 0$

Let the significance level be 0.05.

*  **Calculate**

```{r}
E51d <- function(x1, y1, x2, y2){
  # numbers of sample
  n1 <- length(y1); n2 <- length(y2)
  
  # sample mean
  x1bar <- mean(x1); x2bar <- mean(x2)
  y1bar <- mean(y1); y2bar <- mean(y2)
  
  # OLS coefficient
  b1hat1 <- cov(x1, y1)/var(x1); b1hat2 <- cov(x2, y2)/var(x2)
  b0hat1 <- y1bar - b1hat1*x1bar; b0hat2 <- y2bar - b1hat2*x2bar
  
  y1hat1 <- b0hat1 + b1hat1*x1; y2hat2 <- b0hat2 + b1hat2*x2
  
  # explained sum of squares (ESS)
  ESS1 <- sum((y1hat1 - y1bar)^2); ESS2 <- sum((y2hat2 - y2bar)^2)
  # total sum of squares (TSS)
  TSS1 <- sum((y1 - y1bar)^2); TSS2 <- sum((y2 - y2bar)^2)
  # sum of squared residuals (SSR)
  SSR1 <- sum((y1 - y1hat1)^2); SSR2 <- sum((y2 - y2hat2)^2)
  
  # standard error of the regression
  SER1 <- sqrt(SSR1/(n1-2)); SER2 <- sqrt(SSR2/(n2-2))
  
  # standard error of coefficient
  se_b1hat1 <- sqrt(SER1^2/sum((x1 - x1bar)^2))
  se_b1hat2 <- sqrt(SER2^2/sum((x2 - x2bar)^2))
  
  est <- b1hat1 - b1hat2
  se <- sqrt(se_b1hat1^2 + se_b1hat2^2)
  
  # 95% CI for difference
  lower <- round(est - qnorm(0.975, mean = 0, sd = 1)*se, digit = 4)
  upper <- round(est + qnorm(0.975, mean = 0, sd = 1)*se, digit = 4)
  CI <- paste(lower, "-", upper)  
  
  # output table
  Table <- data.frame(est, se, CI)
  colnames(Table) <- c("Estimate", "Standard Error", "95% Confidence Interval")
  
  Table 
  
}

E51d(Earnings_and_Height_men$height, Earnings_and_Height_men$earnings, Earnings_and_Height_women$height, Earnings_and_Height_women$earnings)
```


*  **Conclude**

Because $0 \notin 95\%$ confidence interval, we reject $H_0$. The estimated slope is statistically significant different from 0.


> e. One explanation for the effect of height on earnings is that some professions require strength, which is correlated with height. Does the effect of height on earnings disappear when the sample is restricted to occupations in which strength is unlikely to be important?

**Solution**

```{r}
E51e <- function(x, y){
  # numbers of sample
  n <- length(y)
  
  # sample mean
  xbar <- mean(x)
  ybar <- mean(y)
  
  # OLS coefficient
  b1hat <- cov(x,y)/var(x)
  b0hat <- ybar - b1hat*xbar
  
  yhat <- b0hat + b1hat*x
  
  # explained sum of squares (ESS)
  ESS <- sum((yhat - ybar)^2)
  # total sum of squares (TSS)
  TSS <- sum((y - ybar)^2)
  # sum of squared residuals (SSR)
  SSR <- sum((y - yhat)^2)
  
  # coefficient of determination
  #Rsqure <- ESS/TSS
  
  # standard error of the regression
  SER <- sqrt(SSR/(n-2))
  
  # standard error of coefficient
  se_b1hat <- sqrt(SER^2/sum((x - xbar)^2))
  
  # 95% CI for b1hat
  lower_b1hat <- round(b1hat - qnorm(0.975, mean = 0, sd = 1)*se_b1hat, digit = 4)
  upper_b1hat <- round(b1hat + qnorm(0.975, mean = 0, sd = 1)*se_b1hat, digit = 4)
  CI_b1hat <- paste(lower_b1hat, "-"  ,upper_b1hat)
  
  Table <- matrix(c(b1hat, se_b1hat, CI_b1hat), nrow = 1)
  colnames(Table) <- c("Estimate", "Standard Error", "95% Confidence Interval")
  
  Table
} 

E51e_output <- matrix(nrow = 15, ncol = 3)

rownames(E51e_output) <- c(1:15)
colnames(E51e_output) <- c("Estimate", "Standard Error", "95% Confidence Interval")

for (i in 1:15){
  data <- Earnings_and_Height[Earnings_and_Height$occupation == i,]
  x <- data$height
  y <- data$earnings
  E51e_output[i,] <- E51e(x, y)
}

E51e_output

```








